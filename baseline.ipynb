{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c556cbd5",
   "metadata": {},
   "source": [
    "**Task Type**: Image Regression\n",
    "\n",
    "**Loss Function**: 平均二乗誤差(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99999b08",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34db6986",
   "metadata": {},
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "687e3d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.8.0\n",
      "Device: MPS (Apple Silicon GPU)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "\n",
    "device_str = \"CPU\"\n",
    "if torch.cuda.is_available():\n",
    "    device_str = f\"CUDA: {torch.cuda.get_device_name(0)}\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device_str = \"MPS (Apple Silicon GPU)\"\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {device_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a5a84",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de3744b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (1785, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>Sampling_Date</th>\n",
       "      <th>State</th>\n",
       "      <th>Species</th>\n",
       "      <th>Pre_GSHH_NDVI</th>\n",
       "      <th>Height_Ave_cm</th>\n",
       "      <th>target_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1011485656__Dry_Clover_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Clover_g</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1011485656__Dry_Dead_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Dead_g</td>\n",
       "      <td>31.9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1011485656__Dry_Green_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Green_g</td>\n",
       "      <td>16.2751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID1011485656__Dry_Total_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Total_g</td>\n",
       "      <td>48.2735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID1011485656__GDM_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>GDM_g</td>\n",
       "      <td>16.2750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sample_id              image_path Sampling_Date State  \\\n",
       "0  ID1011485656__Dry_Clover_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "1    ID1011485656__Dry_Dead_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "2   ID1011485656__Dry_Green_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "3   ID1011485656__Dry_Total_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "4         ID1011485656__GDM_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "\n",
       "           Species  Pre_GSHH_NDVI  Height_Ave_cm   target_name   target  \n",
       "0  Ryegrass_Clover           0.62         4.6667  Dry_Clover_g   0.0000  \n",
       "1  Ryegrass_Clover           0.62         4.6667    Dry_Dead_g  31.9984  \n",
       "2  Ryegrass_Clover           0.62         4.6667   Dry_Green_g  16.2751  \n",
       "3  Ryegrass_Clover           0.62         4.6667   Dry_Total_g  48.2735  \n",
       "4  Ryegrass_Clover           0.62         4.6667         GDM_g  16.2750  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle 上で動いているかどうかを判定\n",
    "ON_KAGGLE = (\"KAGGLE_KERNEL_RUN_TYPE\" in os.environ) or Path(\"/kaggle/input\").exists()\n",
    "\n",
    "if ON_KAGGLE:\n",
    "    PATH_DATA = \"/kaggle/input/csiro-biomass\"\n",
    "else:\n",
    "    PATH_DATA = \"data\"\n",
    "\n",
    "PATH_TRAIN_CSV = os.path.join(PATH_DATA, 'train.csv')\n",
    "PATH_TRAIN_IMG = os.path.join(PATH_DATA, 'train')\n",
    "PATH_TEST_IMG = os.path.join(PATH_DATA, 'test')\n",
    "\n",
    "df = pd.read_csv(PATH_TRAIN_CSV)\n",
    "print(f'Dataset size: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c53f394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target columns: ['target']\n",
      "Number of targets: 1\n"
     ]
    }
   ],
   "source": [
    "TARGET_COLS = [\"target\"]\n",
    "print(f\"Target columns: {TARGET_COLS}\")\n",
    "print(f\"Number of targets: {len(TARGET_COLS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c13a7",
   "metadata": {},
   "source": [
    "### Dataset/DataLoader\n",
    "\n",
    "まずは画像を読み込んで、`TARGET_COLS` と回帰ターゲットとして返す Dataset を定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2172da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 画像サイズはとりあえず 256 にする（後で変えてOK)\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# 画像前処理（最低限）\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    # 正規化はひとまず 0-1 のままでも良いが、\n",
    "    # ちゃんとやるなら mean/std を計算してからここに入れる\n",
    "])\n",
    "\n",
    "\n",
    "class BiomassDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, transform=None, is_train: bool = True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def _load_image(self, image_path: str):\n",
    "        # コンペの画像は .jpg なのでこうしておく (必要なら .png に変更)\n",
    "        img_path = os.path.join(PATH_DATA, image_path)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = self._load_image(row[\"image_path\"])\n",
    "        target = torch.tensor(row[\"target\"], dtype=torch.float32)   # スカラー\n",
    "        return image, target\n",
    "    \n",
    "\n",
    "class BiomassTestDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def _load_image(self, image_path):\n",
    "        image_path = os.path.join(PATH_DATA, image_path)\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = self._load_image(row[\"image_path\"])\n",
    "        sample_id = row[\"sample_id\"]\n",
    "        return image, sample_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ad4cd",
   "metadata": {},
   "source": [
    "簡単に train/valid に分割して DataLoader を作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44974276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_dataset = BiomassDataset(train_df, transform=train_transform)\n",
    "valid_dataset = BiomassDataset(valid_df, transform=train_transform)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b9157",
   "metadata": {},
   "source": [
    "デバイス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e1a6481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de72c7ed",
   "metadata": {},
   "source": [
    "シンプルな CNN ベースライン(画像 -> グローバル平均プーリング -> 全結合で5ターゲット)を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "580d5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNNRegressor(nn.Module):\n",
    "    def __init__(self, num_targets: int):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),    # 256 -> 128\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),    # 128 -> 64\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),    # 64 -> 32\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),    # 32 -> 16\n",
    "        )\n",
    "\n",
    "        # グローバル平均プーリング\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_targets)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = self.regressor(x)\n",
    "        return x\n",
    "    \n",
    "EPOCHS = 10\n",
    "lr = 1e-3\n",
    "\n",
    "model = SimpleCNNRegressor(num_targets=len(TARGET_COLS)).to(device)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8674fd0d",
   "metadata": {},
   "source": [
    "## 学習ループ(MSE)\n",
    "\n",
    "最低限の train/valid ループ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "154d3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_abs_error = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    for images, targets in tqdm(loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)    # shape: (batch, )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).squeeze(-1)  # (batch, 1) -> (batch, )\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_abs_error += torch.abs(outputs - targets).sum().item()\n",
    "        n_samples += images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / n_samples   # MSE\n",
    "    epoch_mae = running_abs_error / n_samples   # MAE\n",
    "    epoch_rmse = np.sqrt(epoch_loss)   # RMSE\n",
    "\n",
    "    return epoch_loss, epoch_mae, epoch_rmse\n",
    "\n",
    "\n",
    "def eval_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_abs_error = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(loader):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(images).squeeze(-1)  # (batch, 1) -> (batch, )\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_abs_error += torch.abs(outputs - targets).sum().item()\n",
    "            n_samples += images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / n_samples   # MSE\n",
    "    epoch_mae = running_abs_error / n_samples  # MAE\n",
    "    epoch_rmse = np.sqrt(epoch_loss)   # RMSE\n",
    "\n",
    "    return epoch_loss, epoch_mae, epoch_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f48e7602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:32<00:00,  2.73it/s]\n",
      "100%|██████████| 23/23 [00:07<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10] Train [MSE: 767.1125, RMSE: 27.6968, MAE: 20.0554] Valid [MSE: 663.5529, RMSE: 25.7595, MAE: 19.0635]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:33<00:00,  2.70it/s]\n",
      "100%|██████████| 23/23 [00:08<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train [MSE: 662.5005, RMSE: 25.7391, MAE: 19.2468] Valid [MSE: 651.3030, RMSE: 25.5206, MAE: 19.6599]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:33<00:00,  2.68it/s]\n",
      "100%|██████████| 23/23 [00:08<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Train [MSE: 664.6426, RMSE: 25.7807, MAE: 19.1852] Valid [MSE: 735.3812, RMSE: 27.1179, MAE: 18.6325]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:33<00:00,  2.71it/s]\n",
      "100%|██████████| 23/23 [00:07<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] Train [MSE: 657.4320, RMSE: 25.6404, MAE: 18.8949] Valid [MSE: 651.6372, RMSE: 25.5272, MAE: 19.4035]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:33<00:00,  2.67it/s]\n",
      "100%|██████████| 23/23 [00:08<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] Train [MSE: 634.0869, RMSE: 25.1811, MAE: 18.5428] Valid [MSE: 671.9912, RMSE: 25.9228, MAE: 20.2197]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:33<00:00,  2.68it/s]\n",
      "100%|██████████| 23/23 [00:08<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] Train [MSE: 640.1495, RMSE: 25.3012, MAE: 18.6231] Valid [MSE: 690.1687, RMSE: 26.2711, MAE: 18.2605]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:33<00:00,  2.67it/s]\n",
      "100%|██████████| 23/23 [00:08<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] Train [MSE: 645.5098, RMSE: 25.4069, MAE: 18.6684] Valid [MSE: 644.2566, RMSE: 25.3822, MAE: 18.8143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:33<00:00,  2.71it/s]\n",
      "100%|██████████| 23/23 [00:07<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] Train [MSE: 638.6351, RMSE: 25.2712, MAE: 18.6142] Valid [MSE: 716.1050, RMSE: 26.7601, MAE: 18.4206]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:33<00:00,  2.69it/s]\n",
      "100%|██████████| 23/23 [00:08<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] Train [MSE: 646.4843, RMSE: 25.4261, MAE: 18.5986] Valid [MSE: 653.6382, RMSE: 25.5663, MAE: 18.3104]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:33<00:00,  2.71it/s]\n",
      "100%|██████████| 23/23 [00:07<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] Train [MSE: 638.0806, RMSE: 25.2603, MAE: 18.6401] Valid [MSE: 654.2559, RMSE: 25.5784, MAE: 19.2559]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_mae, train_rmse = train_one_epoch(model, train_loader, loss_function, optimizer, device)\n",
    "    valid_loss, valid_mae, valid_rmse = eval_one_epoch(model, valid_loader, loss_function, device)\n",
    "\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch}/{EPOCHS}] \"\n",
    "        f\"Train [MSE: {train_loss:.4f}, RMSE: {train_rmse:.4f}, MAE: {train_mae:.4f}] \"\n",
    "        f\"Valid [MSE: {valid_loss:.4f}, RMSE: {valid_rmse:.4f}, MAE: {valid_mae:.4f}]\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec49f4",
   "metadata": {},
   "source": [
    "## テスト実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dea90a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g  20.751219\n",
      "1    ID1001187975__Dry_Dead_g  20.751219\n",
      "2   ID1001187975__Dry_Green_g  20.751219\n",
      "3   ID1001187975__Dry_Total_g  20.751219\n",
      "4         ID1001187975__GDM_g  20.751219\n",
      "(5, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PATH_TEST_CSV = os.path.join(PATH_DATA, \"test.csv\")\n",
    "test_df = pd.read_csv(PATH_TEST_CSV)\n",
    "test_df.head()\n",
    "\n",
    "test_dataset = BiomassTestDataset(test_df, transform=train_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "model.eval()\n",
    "all_sample_ids = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, sample_ids in tqdm(test_loader):\n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs = model(images).squeeze(-1)\n",
    "        preds = outputs.cpu().numpy()\n",
    "\n",
    "        all_sample_ids.extend(sample_ids)\n",
    "        all_preds.extend(preds)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"sample_id\": all_sample_ids,\n",
    "    \"target\": all_preds,\n",
    "})\n",
    "\n",
    "print(submission.head())\n",
    "print(submission.shape)\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
