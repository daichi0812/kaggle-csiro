{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c556cbd5",
   "metadata": {},
   "source": [
    "**Task Type**: Image Regression\n",
    "\n",
    "**Loss Function**: 平均二乗誤差(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99999b08",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34db6986",
   "metadata": {},
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "687e3d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.8.0\n",
      "Device: MPS (Apple Silicon GPU)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "\n",
    "device_str = \"CPU\"\n",
    "if torch.cuda.is_available():\n",
    "    device_str = f\"CUDA: {torch.cuda.get_device_name(0)}\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device_str = \"MPS (Apple Silicon GPU)\"\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {device_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a5a84",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de3744b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (1785, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>Sampling_Date</th>\n",
       "      <th>State</th>\n",
       "      <th>Species</th>\n",
       "      <th>Pre_GSHH_NDVI</th>\n",
       "      <th>Height_Ave_cm</th>\n",
       "      <th>target_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1011485656__Dry_Clover_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Clover_g</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1011485656__Dry_Dead_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Dead_g</td>\n",
       "      <td>31.9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1011485656__Dry_Green_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Green_g</td>\n",
       "      <td>16.2751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID1011485656__Dry_Total_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Total_g</td>\n",
       "      <td>48.2735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID1011485656__GDM_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>GDM_g</td>\n",
       "      <td>16.2750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sample_id              image_path Sampling_Date State  \\\n",
       "0  ID1011485656__Dry_Clover_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "1    ID1011485656__Dry_Dead_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "2   ID1011485656__Dry_Green_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "3   ID1011485656__Dry_Total_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "4         ID1011485656__GDM_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "\n",
       "           Species  Pre_GSHH_NDVI  Height_Ave_cm   target_name   target  \n",
       "0  Ryegrass_Clover           0.62         4.6667  Dry_Clover_g   0.0000  \n",
       "1  Ryegrass_Clover           0.62         4.6667    Dry_Dead_g  31.9984  \n",
       "2  Ryegrass_Clover           0.62         4.6667   Dry_Green_g  16.2751  \n",
       "3  Ryegrass_Clover           0.62         4.6667   Dry_Total_g  48.2735  \n",
       "4  Ryegrass_Clover           0.62         4.6667         GDM_g  16.2750  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kaggle 上で動いているかどうかを判定\n",
    "ON_KAGGLE = (\"KAGGLE_KERNEL_RUN_TYPE\" in os.environ) or Path(\"/kaggle/input\").exists()\n",
    "\n",
    "if ON_KAGGLE:\n",
    "    PATH_DATA = \"/kaggle/input/csiro-biomass\"\n",
    "else:\n",
    "    PATH_DATA = \"data\"\n",
    "\n",
    "PATH_TRAIN_CSV = os.path.join(PATH_DATA, 'train.csv')\n",
    "PATH_TRAIN_IMG = os.path.join(PATH_DATA, 'train')\n",
    "PATH_TEST_IMG = os.path.join(PATH_DATA, 'test')\n",
    "\n",
    "df = pd.read_csv(PATH_TRAIN_CSV)\n",
    "print(f'Dataset size: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c53f394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target columns: ['target']\n",
      "Number of targets: 1\n"
     ]
    }
   ],
   "source": [
    "TARGET_COLS = [\"target\"]\n",
    "print(f\"Target columns: {TARGET_COLS}\")\n",
    "print(f\"Number of targets: {len(TARGET_COLS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c13a7",
   "metadata": {},
   "source": [
    "### Dataset/DataLoader\n",
    "\n",
    "まずは画像を読み込んで、`TARGET_COLS` と回帰ターゲットとして返す Dataset を定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2172da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 画像サイズはとりあえず 256 にする（後で変えてOK)\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# 画像前処理（最低限）\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    # 正規化はひとまず 0-1 のままでも良いが、\n",
    "    # ちゃんとやるなら mean/std を計算してからここに入れる\n",
    "])\n",
    "\n",
    "\n",
    "class BiomassDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, transform=None, is_train: bool = True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def _load_image(self, image_path: str):\n",
    "        # コンペの画像は .jpg なのでこうしておく (必要なら .png に変更)\n",
    "        img_path = os.path.join(PATH_DATA, image_path)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = self._load_image(row[\"image_path\"])\n",
    "        target = torch.tensor(row[\"target\"], dtype=torch.float32)   # スカラー\n",
    "        return image, target\n",
    "    \n",
    "\n",
    "class BiomassTestDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def _load_image(self, image_path):\n",
    "        image_path = os.path.join(PATH_DATA, image_path)\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = self._load_image(row[\"image_path\"])\n",
    "        sample_id = row[\"sample_id\"]\n",
    "        return image, sample_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ad4cd",
   "metadata": {},
   "source": [
    "簡単に train/valid に分割して DataLoader を作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44974276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_dataset = BiomassDataset(train_df, transform=train_transform)\n",
    "valid_dataset = BiomassDataset(valid_df, transform=train_transform)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b9157",
   "metadata": {},
   "source": [
    "デバイス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e1a6481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de72c7ed",
   "metadata": {},
   "source": [
    "シンプルな CNN ベースライン(画像 -> グローバル平均プーリング -> 全結合で5ターゲット)を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "580d5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNNRegressor(nn.Module):\n",
    "    def __init__(self, num_targets: int):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),    # 256 -> 128\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),    # 128 -> 64\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),    # 64 -> 32\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),    # 32 -> 16\n",
    "        )\n",
    "\n",
    "        # グローバル平均プーリング\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_targets)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = self.regressor(x)\n",
    "        return x\n",
    "    \n",
    "EPOCHS = 10\n",
    "lr = 1e-3\n",
    "\n",
    "model = SimpleCNNRegressor(num_targets=len(TARGET_COLS)).to(device)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8674fd0d",
   "metadata": {},
   "source": [
    "## 学習ループ(MSE)\n",
    "\n",
    "最低限の train/valid ループ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "154d3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_abs_error = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    for images, targets in tqdm(loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)    # shape: (batch, )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).squeeze(-1)  # (batch, 1) -> (batch, )\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_abs_error += torch.abs(outputs - targets).sum().item()\n",
    "        n_samples += images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / n_samples   # MSE\n",
    "    epoch_mae = running_abs_error / n_samples   # MAE\n",
    "    epoch_rmse = np.sqrt(epoch_loss)   # RMSE\n",
    "\n",
    "    return epoch_loss, epoch_mae, epoch_rmse\n",
    "\n",
    "\n",
    "def eval_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_abs_error = 0.0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(loader):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(images).squeeze(-1)  # (batch, 1) -> (batch, )\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_abs_error += torch.abs(outputs - targets).sum().item()\n",
    "            n_samples += images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / n_samples   # MSE\n",
    "    epoch_mae = running_abs_error / n_samples  # MAE\n",
    "    epoch_rmse = np.sqrt(epoch_loss)   # RMSE\n",
    "\n",
    "    return epoch_loss, epoch_mae, epoch_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f48e7602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:31<00:00,  2.83it/s]\n",
      "100%|██████████| 23/23 [00:07<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10] Train [MSE: 713.7574, RMSE: 26.7162, MAE: 19.7233] Valid [MSE: 674.0899, RMSE: 25.9632, MAE: 18.4611]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:32<00:00,  2.78it/s]\n",
      "100%|██████████| 23/23 [00:07<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train [MSE: 642.3713, RMSE: 25.3450, MAE: 18.7341] Valid [MSE: 666.1173, RMSE: 25.8092, MAE: 18.2572]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:32<00:00,  2.75it/s]\n",
      "100%|██████████| 23/23 [00:07<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Train [MSE: 659.8623, RMSE: 25.6878, MAE: 18.7755] Valid [MSE: 643.7601, RMSE: 25.3724, MAE: 19.1142]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:32<00:00,  2.74it/s]\n",
      "100%|██████████| 23/23 [00:07<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] Train [MSE: 637.7630, RMSE: 25.2540, MAE: 18.6256] Valid [MSE: 674.5952, RMSE: 25.9730, MAE: 18.2204]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:32<00:00,  2.73it/s]\n",
      "100%|██████████| 23/23 [00:07<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] Train [MSE: 639.1688, RMSE: 25.2818, MAE: 18.6796] Valid [MSE: 643.5467, RMSE: 25.3682, MAE: 18.4356]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:33<00:00,  2.72it/s]\n",
      "100%|██████████| 23/23 [00:08<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] Train [MSE: 652.8797, RMSE: 25.5515, MAE: 18.8062] Valid [MSE: 658.1561, RMSE: 25.6546, MAE: 18.1983]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:33<00:00,  2.68it/s]\n",
      "100%|██████████| 23/23 [00:08<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] Train [MSE: 637.5385, RMSE: 25.2495, MAE: 18.6775] Valid [MSE: 684.1753, RMSE: 26.1567, MAE: 18.1904]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:34<00:00,  2.64it/s]\n",
      "100%|██████████| 23/23 [00:08<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] Train [MSE: 656.6500, RMSE: 25.6252, MAE: 18.7885] Valid [MSE: 675.5258, RMSE: 25.9909, MAE: 20.2465]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:33<00:00,  2.67it/s]\n",
      "100%|██████████| 23/23 [00:08<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] Train [MSE: 623.1977, RMSE: 24.9639, MAE: 18.3328] Valid [MSE: 661.0443, RMSE: 25.7108, MAE: 18.1226]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:34<00:00,  2.65it/s]\n",
      "100%|██████████| 23/23 [00:07<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] Train [MSE: 680.1725, RMSE: 26.0801, MAE: 18.9953] Valid [MSE: 668.4805, RMSE: 25.8550, MAE: 18.1823]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_mae, train_rmse = train_one_epoch(model, train_loader, loss_function, optimizer, device)\n",
    "    valid_loss, valid_mae, valid_rmse = eval_one_epoch(model, valid_loader, loss_function, device)\n",
    "\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch}/{EPOCHS}] \"\n",
    "        f\"Train [MSE: {train_loss:.4f}, RMSE: {train_rmse:.4f}, MAE: {train_mae:.4f}] \"\n",
    "        f\"Valid [MSE: {valid_loss:.4f}, RMSE: {valid_rmse:.4f}, MAE: {valid_mae:.4f}]\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec49f4",
   "metadata": {},
   "source": [
    "## テスト実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dea90a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BiomassTestDataset' object has no attribute 'trainsform'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m all_preds = []\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/kaggle/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/kaggle/lib/python3.12/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/kaggle/lib/python3.12/site-packages/torch/utils/data/dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/kaggle/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mBiomassTestDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m     55\u001b[39m     row = \u001b[38;5;28mself\u001b[39m.df.iloc[idx]\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     image = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage_path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     sample_id = row[\u001b[33m\"\u001b[39m\u001b[33msample_id\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m image, sample_id\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mBiomassTestDataset._load_image\u001b[39m\u001b[34m(self, image_path)\u001b[39m\n\u001b[32m     48\u001b[39m image_path = os.path.join(PATH_DATA, image_path)\n\u001b[32m     49\u001b[39m img = Image.open(image_path).convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainsform\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     51\u001b[39m     img = \u001b[38;5;28mself\u001b[39m.transform(img)\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[31mAttributeError\u001b[39m: 'BiomassTestDataset' object has no attribute 'trainsform'"
     ]
    }
   ],
   "source": [
    "PATH_TEST_CSV = os.path.join(PATH_DATA, \"test.csv\")\n",
    "test_df = pd.read_csv(PATH_TEST_CSV)\n",
    "test_df.head()\n",
    "\n",
    "test_dataset = BiomassTestDataset(test_df, transform=train_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "model.eval()\n",
    "all_sample_ids = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, sample_ids in tqdm(test_loader):\n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs = model(images).squeeze(-1)\n",
    "        preds = outputs.cpu().numpy()\n",
    "\n",
    "        all_sample_ids.extend(sample_ids)\n",
    "        all_preds.extend(preds)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"sample_id\": all_sample_ids,\n",
    "    \"target\": all_preds,\n",
    "})\n",
    "\n",
    "print(submission.head())\n",
    "print(submission.shape)\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
